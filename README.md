# Machine Learning Analysis of the Art Institute of Chicago

# Background:

In this project, we employ Machine Learning to analyze the art collections housed at the Art Institute of Chicago. We utilize variables such as the nationality of the artist, view, category title, and type of artwork to analyze the frequency of historical exhibitions of the artworks and delve into the backgrounds of the artists. The primary question addressed in this project is the application of Machine Learning to predict the next artwork likely to be displayed.


# Project Requirements:

Data Model Implementation: The Python script initializes, trains, and evaluates the model, performs data cleansing and normalization, utilizes data retrieved from SQLite, and demonstrates the model's meaningful predictive power with a minimum classification accuracy of 75% or an R-Squared value of 0.85.

Data Model Optimization: Changes made during the optimization and evaluation process are documented in a CSV file and displayed at the end of the script.

GitHub Documentation: The README contains the contents of the project.

Group Presentation: All group members present smoothly within the time restrictions and maintain audience interest.



# Tools Used for DataFrame and Visualizations:

Pandas: A powerful Python library for data manipulation and analysis, offering easy-to-use data structures and tools for tasks such as reading and writing data, cleaning and transforming data, and performing complex operations on tabular data.

SQLite3: A lightweight, serverless, self-contained SQL database engine used for creating, reading, updating, and deleting data in a relational database, providing a convenient way to store and manage structured data.

Scikit-learn (sklearn): A popular machine learning library in Python that provides simple and efficient tools for data mining and analysis, including a wide range of machine learning algorithms for classification, regression, clustering, and dimensionality reduction, as well as tools for model selection and evaluation.

TensorFlow: An open-source machine learning framework developed by Google for building and training neural network models. It offers a comprehensive ecosystem of tools, libraries, and community resources for deep learning, including support for both research and production deployments.

Keras: A high-level neural networks API written in Python, capable of running on top of TensorFlow. It provides a user-friendly interface for building, training, and deploying deep learning models, enabling fast experimentation and prototyping of neural networks for both beginners and experts in the field.

